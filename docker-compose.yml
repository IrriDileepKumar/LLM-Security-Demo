version: "3.8"
services:
  ollama:
    image: ollama/ollama
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_KEEP_ALIVE=24h
      - OLLAMA_NUM_PARALLEL=2 # Limit parallel requests for better performance
      - OLLAMA_LOAD_TIMEOUT=300 # 5 minutes for model loading
      - OLLAMA_MAX_QUEUE=10 # Smaller queue to prevent overload
      - OLLAMA_MAX_LOADED_MODELS=2 # Limit concurrent models
    restart: always

  app:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    ports:
      - "5000:5000"
    depends_on:
      - ollama
    environment:
      OLLAMA_HOST: http://ollama:11434
      ENVIRONMENT: production
      NODE_ENV: production
    volumes:
      - ./content:/app/content

volumes:
  ollama_data:
